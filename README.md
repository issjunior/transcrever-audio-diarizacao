## Como funciona üîé

- Whisper ‚Üí Transcreve o √°udio e gera segmentos com timestamps.
- Pyannote ‚Üí Detecta os locutores e seus intervalos de fala.

O script cruza os intervalos de tempo e atribui cada trecho ao locutor correto.
Exporta em um Word (.docx) organizado em colunas:

- Tempo
- Locutor
- Transcri√ß√£o

---

## Funcionalidades

- Transcri√ß√£o de √°udio em texto usando **OpenAI Whisper**.
- Identifica√ß√£o de locutores usando **pyannote.audio** (diariza√ß√£o de fala).
- Exporta√ß√£o da transcri√ß√£o em arquivo **Word (.docx)** organizado por tempo e locutor.

---

## Requisitos

- Python 3.10+  
- Bibliotecas Python:

```bash
pip install openai-whisper pyannote.audio python-docx
```

---

## Como usar
### 1. Coloque o √°udio que deseja transcrever na pasta do projeto (ex: exemplo.mp3).
### 2. Edite o arquivo Python com seu token Hugging Face:
```python
HUGGINGFACE_TOKEN = "seu_token_aqui"
```
#### O pipeline pyannote/speaker-diarization precisa de acesso autenticado ao Hugging Face.

### 3.Execute o script:
```bash
python transcrever.py
```
### 4. O resultado ser√° exportado para transcricao_diarizada.docx.
---

## Sa√≠da esperada

```csharp
[00:00 - 00:12] Speaker 1: Bom dia, tudo bem?
[00:12 - 00:20] Speaker 2: Tudo sim, e voc√™?
[00:20 - 00:25] Speaker 1: Tamb√©m, obrigado.
```

